{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viswambhar-yasa/image_captioning/blob/master/training_reward_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCaXLacBGeyg",
        "outputId": "fe2f4d8b-3044-4966-8f75-d1fa58e1c6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'image_captioning'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 22 (delta 8), reused 15 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/viswambhar-yasa/image_captioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VsGCW4z_Gi35"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "def downloading_extraction(link, extraction_path='.'):\n",
        "    url = urlopen(link)\n",
        "    zipfile = ZipFile(BytesIO(url.read()))\n",
        "    zipfile.extractall(path=extraction_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    images_link = 'https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip'\n",
        "    downloading_extraction(images_link)\n",
        "    text_link = \"https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\"\n",
        "    downloading_extraction(text_link)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Embedding, LSTM, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.applications import Xception, InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.keras.layers.recurrent import GRU\n",
        "\n",
        "\n",
        "def image_encoder(img_input, trainable_layers=0, CNN_Type='Xception', Embed_Size=256, display=False):\n",
        "    print('Building CNN model')\n",
        "    if CNN_Type == 'Xception':\n",
        "        cnn_pre_trained_model = Xception(include_top=False, weights='imagenet', input_tensor=img_input)\n",
        "    else:\n",
        "        cnn_pre_trained_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=img_input)\n",
        "    for i, layer in enumerate(cnn_pre_trained_model.layers):\n",
        "        if len(cnn_pre_trained_model.layers) - i < trainable_layers:\n",
        "            layer.trainable = True\n",
        "        else:\n",
        "            layer.trainable = False\n",
        "    cnn_inputs = cnn_pre_trained_model.inputs\n",
        "    base_model = cnn_pre_trained_model.output\n",
        "    base_model = GlobalAveragePooling2D(name='global_average_pooling')(base_model)\n",
        "    embed_image = tf.keras.layers.Dense(Embed_Size, activation='tanh', name='embed_image')(base_model)\n",
        "    feature_extraction_model = Model(inputs=cnn_inputs, outputs=embed_image, name='CNN encoder model')\n",
        "    print('CNN model {output shape}:', embed_image.shape)\n",
        "    if display:\n",
        "        tf.keras.utils.plot_model(feature_extraction_model, to_file='base_model.png', show_shapes=True)\n",
        "    return feature_extraction_model\n",
        "\n",
        "\n",
        "def txt_decoder(rnn_input, Embed_Size=256, Bi_Direction=False, RNN_Type='LSTM', RNN_Layers=2):\n",
        "    print('Building RNN model')\n",
        "    for i in range(RNN_Layers):\n",
        "        x = BatchNormalization()(rnn_input)\n",
        "        if RNN_Type == 'LSTM':\n",
        "            if i == (RNN_Layers - 1):\n",
        "                if Bi_Direction:\n",
        "                    rnn_out = Bidirectional(LSTM(int(Embed_Size/2)))(x)\n",
        "                else:\n",
        "                    rnn_out = LSTM(Embed_Size)(x)\n",
        "            else:\n",
        "                if Bi_Direction:\n",
        "                    rnn_out = Bidirectional(LSTM(int(Embed_Size/2), return_sequences=True))(x)\n",
        "                else:\n",
        "                    rnn_out = LSTM(Embed_Size, return_sequences=True)(x)\n",
        "        else:\n",
        "            if i == (RNN_Layers - 1):\n",
        "                if Bi_Direction:\n",
        "                    rnn_out = Bidirectional(GRU(Embed_Size))(x)\n",
        "                else:\n",
        "                    rnn_out = GRU(Embed_Size)(x)\n",
        "            else:\n",
        "                if Bi_Direction:\n",
        "                    rnn_out = Bidirectional(GRU(Embed_Size/2, return_sequences=True))(x)\n",
        "                else:\n",
        "                    rnn_out = GRU(Embed_Size, return_sequences=True)(x)\n",
        "        rnn_input = rnn_out\n",
        "    return rnn_out\n",
        "\n",
        "\n",
        "def Caption_model_gen(NET, img_shape=(256, 256, 3), vocab_size=8763, Embed_Size=512, max_length=20, display=False):\n",
        "    img_input = tf.keras.Input(shape=img_shape)\n",
        "    cnn_model = image_encoder(img_input, trainable_layers=0, CNN_Type='InceptionV3', display=False)\n",
        "    embed_image = tf.keras.layers.Dense(Embed_Size, activation='tanh')(cnn_model.output)\n",
        "\n",
        "    text_input = tf.keras.Input(shape=(max_length,))\n",
        "    Embedding_layer = Embedding(input_dim=vocab_size, output_dim=Embed_Size, input_length=max_length, mask_zero=True)(\n",
        "        text_input)\n",
        "\n",
        "    whole_seq_output = txt_decoder(Embedding_layer, Embed_Size=Embed_Size,\n",
        "                                                                          Bi_Direction=False, RNN_Type='LSTM',\n",
        "                                                                          RNN_Layers=1)\n",
        "    print('final_carry_state {rnn output shape}:', whole_seq_output.shape)\n",
        "    rnn_output = whole_seq_output\n",
        "    if NET == 'policy':\n",
        "        image_txt_embed = tf.keras.layers.add([embed_image, rnn_output])\n",
        "        print('Image and text {add shape}:', image_txt_embed.shape)\n",
        "        policy_net_output = tf.keras.layers.Dense(vocab_size, activation='softmax')(image_txt_embed)\n",
        "        policy_net_model = Model(inputs=[img_input, text_input], outputs=policy_net_output, name='Policy_Net')\n",
        "\n",
        "        print('output {shape}', policy_net_output.shape)\n",
        "        print('Policy Net built successfully \\n')\n",
        "        if display:\n",
        "            tf.keras.utils.plot_model(policy_net_model, to_file='policy_net.png', show_shapes=True)\n",
        "        return policy_net_model\n",
        "    elif NET == 'value':\n",
        "        image_txt_embed = tf.keras.layers.concatenate([embed_image, rnn_output], axis=-1)\n",
        "        print('Image and text {concat shape}:', image_txt_embed.shape)\n",
        "        hidden_layer_1 = Dense(1024, activation='tanh', name='MLP_layer1')(image_txt_embed)\n",
        "        hidden_layer_2 = Dense(512, activation='tanh', name=\"MLP_layer2\")(hidden_layer_1)\n",
        "        value_net_outputs = Dense(1, activation='tanh', name='decoder_output')(hidden_layer_2)\n",
        "        value_net_model = Model(inputs=[img_input, text_input], outputs=value_net_outputs, name='Value_Net')\n",
        "        print('output {shape}', value_net_outputs.shape)\n",
        "        print('Value Net built successfully \\n')\n",
        "        if display:\n",
        "            tf.keras.utils.plot_model(value_net_model, to_file='value_net.png', show_shapes=True)\n",
        "        return value_net_model\n",
        "    else:\n",
        "        feature_vector = Dense(512, activation='tanh')(embed_image)\n",
        "        text_sequence_vector = Dense(512, activation='tanh', name='rnn_linear')(rnn_output)\n",
        "        print('Image feature vector shape:', feature_vector.shape)\n",
        "        print('Text sequence vector shape:', text_sequence_vector.shape)\n",
        "        reward_model = Model(inputs=[img_input, text_input], outputs=[feature_vector, text_sequence_vector],\n",
        "                             name='reward_net_model')\n",
        "        print('Reward Net built successfully \\n')\n",
        "        if display:\n",
        "            tf.keras.utils.plot_model(reward_model, to_file='reward_net.png', show_shapes=True)\n",
        "        return reward_model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print('TensorFlow Version', tf.__version__)\n",
        "    #actor_model = Caption_model_gen('policy')\n",
        "    #critic_model = Caption_model_gen('value')\n",
        "    #reward = Caption_model_gen('reward')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "907XvN7wzXz3",
        "outputId": "da1c57ea-2466-4478-b53b-e3afaeb46c34"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2fEKMu1e4XxR"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/image_captioning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDfI0dk_6FSr",
        "outputId": "bed29842-e2e0-4fb7-bffa-eb72222e3b58"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/image_captioning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class data_processing:\n",
        "    def __init__(self, text_file_path):\n",
        "        self.text_file_path = text_file_path\n",
        "        self.tokenizer = None\n",
        "\n",
        "    def extraction_captions(self, images_id_text):\n",
        "        description_map = dict()\n",
        "        text = open(self.text_file_path, 'r', encoding='utf-8').read()\n",
        "        images = open(images_id_text, 'r', encoding='utf-8').read()\n",
        "        img_dic = []\n",
        "        for img_id in images.split('\\n'):\n",
        "            img_dic.append(img_id)\n",
        "        for lines in text.split('\\n'):\n",
        "            line_split = lines.split('\\t')\n",
        "            if line_split == ['']:\n",
        "                continue\n",
        "            image_id = line_split[0][:-2]\n",
        "            image_des = line_split[1]\n",
        "            if image_id in img_dic:\n",
        "                if image_id not in description_map:\n",
        "                    description_map[image_id] = list()\n",
        "                description_map[image_id].append(image_des)\n",
        "        return description_map\n",
        "\n",
        "    def cleaning_sequencing_captions(self, images_id_text):\n",
        "        captions_dic = self.extraction_captions(images_id_text)\n",
        "        caption_list = []\n",
        "        for img_id, des_list in captions_dic.items():\n",
        "            for i in range(len(des_list)):\n",
        "                caption = des_list[i]\n",
        "                caption = ''.join(caption)\n",
        "                caption = caption.split(' ')\n",
        "                caption = [word.lower() for word in caption if len(word) > 1 and word.isalpha()]\n",
        "                caption = ' '.join(caption)\n",
        "                des_list[i] = 'startseq ' + caption + ' endseq'\n",
        "                caption_list.append('startseq ' + caption + ' endseq')\n",
        "        max_length = max(len(des.split()) for des in caption_list)\n",
        "        print('max_length of captions', max_length)\n",
        "        return caption_list,captions_dic\n",
        "\n",
        "    def tokenization(self, captions_for_token, num_wrds=5000) -> None:\n",
        "        tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_wrds, oov_token='<unknw>')\n",
        "        tokenizer.fit_on_texts(captions_for_token)\n",
        "        self.tokenizer = tokenizer\n",
        "        pass\n",
        "\n",
        "    def sentence_tokenizing(self, captions_dic) -> dict:\n",
        "        token_cap_dic = dict()\n",
        "        print('Vocab size', self.tokenizer.num_words)\n",
        "        for img_id, des_list in captions_dic.items():\n",
        "            for i in range(len(des_list)):\n",
        "                caption = des_list[i]\n",
        "                cap_token = self.tokenizer.texts_to_sequences([str(caption)])\n",
        "                if img_id not in token_cap_dic:\n",
        "                    token_cap_dic[img_id] = list()\n",
        "                token_cap_dic[img_id].append(cap_token)\n",
        "        return token_cap_dic"
      ],
      "metadata": {
        "id": "d9Oaedi_FrHA"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('/content/Flickr8k.token.txt', 'r', encoding='utf-8').read()\n",
        "description_map=dict()\n",
        "for lines in text.split('\\n'):\n",
        "  line_split = lines.split('\\t')\n",
        "  if line_split == ['']:\n",
        "      continue\n",
        "  image_id = line_split[0][:-2]\n",
        "  image_des = line_split[1]\n",
        "  #if image_id in img_dic:\n",
        "  if image_id not in description_map:\n",
        "    description_map[image_id] = list()\n",
        "  description_map[image_id].append(image_des)\n",
        "caption_list = []\n",
        "for img_id, des_list in description_map.items():\n",
        "    for i in range(len(des_list)):\n",
        "        caption = des_list[i]\n",
        "        caption = ''.join(caption)\n",
        "        caption = caption.split(' ')\n",
        "        caption = [word.lower() for word in caption if len(word) > 1 and word.isalpha()]\n",
        "        caption = ' '.join(caption)\n",
        "        des_list[i] = 'startseq ' + caption + ' endseq'\n",
        "        caption_list.append('startseq ' + caption + ' endseq')\n",
        "max_length = max(len(des.split()) for des in caption_list)\n",
        "print('max_length of captions', max_length)\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000,oov_token='<unknw>')\n",
        "tokenizer.fit_on_texts(caption_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCxkk8Ty8mpW",
        "outputId": "00e4594e-8866-4cec-959e-d9be38a8e692"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_length of captions 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files=os.listdir(path = '/content/Flicker8k_Dataset')"
      ],
      "metadata": {
        "id": "L4oae4hhl4yN"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description_map1=dict()\n",
        "for key,value in description_map.items():\n",
        "  if key in files:\n",
        "    description_map1[key]=value"
      ],
      "metadata": {
        "id": "E2ljDIH1l1vU"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description_map['2258277193_586949ec62.jpg'] = description_map['2258277193_586949ec62.jpg.1']\n",
        "del description_map['2258277193_586949ec62.jpg.1']"
      ],
      "metadata": {
        "id": "oCL4cB4c8vIn"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del description_map['2258277193_586949ec62.jpg']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "-U9rQRskAzn6",
        "outputId": "a76c2a12-97ce-44c5-f5a7-904ec14c4a19"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-160-4e5a028e6ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdescription_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2258277193_586949ec62.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: '2258277193_586949ec62.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_cap_dic = dict()\n",
        "print('Vocab size',len(tokenizer.word_counts))\n",
        "for img_id, des_list in description_map1.items():\n",
        "    for i in range(len(des_list)):\n",
        "        caption = des_list[i]\n",
        "        cap_token = tokenizer.texts_to_sequences([str(caption)])\n",
        "        if img_id not in token_cap_dic:\n",
        "            token_cap_dic[img_id] = list()\n",
        "        token_cap_dic[img_id].append(cap_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRgYspUC9KLe",
        "outputId": "4e4339b9-d9c6-4ccf-ccc6-18604c7a9ab9"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size 8359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reward_net_loss(visual_features,sematic_featurres,margin=0.2):\n",
        "    #bi-directional max-margin ranking loss (Bi-MMRL)\n",
        "    #visual=tf.ones(shape=(32,512))\n",
        "    #sematic=tf.ones(shape=(32,512))\n",
        "    B=visual_features.shape[0]\n",
        "    remove_diagonal_matrix=tf.ones(B)-tf.eye(B)\n",
        "    similarity_score_1=tf.einsum(\"ij,kj->ik\",visual_features,sematic_featurres)\n",
        "    similarity_score_2=tf.einsum(\"ij,kj->ki\",visual_features,sematic_featurres)\n",
        "    diagonal=tf.einsum(\"ii->i\",similarity_score_1)\n",
        "    s_ii=tf.eye(B)*tf.transpose(diagonal)\n",
        "    loss1=tf.reduce_sum(tf.maximum(0,margin+(similarity_score_1*remove_diagonal_matrix)-s_ii))\n",
        "    loss2=tf.reduce_sum(tf.maximum(0,margin+(similarity_score_2*remove_diagonal_matrix)-s_ii))\n",
        "    rn_loss=(loss1+loss2)*(1/B)\n",
        "    #birectional hard-negatives ranking loss (Bi-HNRL)\n",
        "    #loss1=tf.reduce_sum(tf.maximum(0,margin+(tf.eye(B)*tf.transpose(tf.argmax(similarity_score_1)))-s_ii))\n",
        "    #loss2=tf.reduce_sum(tf.maximum(0,margin+(tf.eye(B)*tf.transpose(tf.argmax(similarity_score_2)))-s_ii))\n",
        "    #loss=loss1+loss2\n",
        "    #loss\n",
        "    return rn_loss"
      ],
      "metadata": {
        "id": "98xuF71SBqSU"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "import numpy as np\n",
        "from data_processing import data_processing\n",
        "\n",
        "\n",
        "def load_preprocess_img(img_path):\n",
        "    img = load_img(img_path, target_size=(256, 256, 3))\n",
        "    x = img_to_array(img)\n",
        "    x /= 255.0\n",
        "    return x\n",
        "\n",
        "\n",
        "def captions_generation_reward(captions_dic, vocab_size, image_pth_rt, max_length=25, num_photos_per_batch=5, num_captions=1):\n",
        "    images, input_text_seq = list(), list()\n",
        "    batch_iter = 0\n",
        "    batch_keys = []\n",
        "    while True:\n",
        "        for key, desc_list in captions_dic.items():\n",
        "            # print(key)\n",
        "            batch_keys.append(key)\n",
        "            batch_iter += 1\n",
        "            caption = 0\n",
        "            # retrieve the photo feature\n",
        "            photo = load_preprocess_img(image_pth_rt + key)\n",
        "            for desc in desc_list:\n",
        "                desc = np.squeeze(desc)\n",
        "                input_sequence=[]\n",
        "                for i in range(0, len(desc)-1):\n",
        "                    input_sequence.append(desc[:i+1])\n",
        "                    images.append(photo)\n",
        "                caption += 1\n",
        "                input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_sequence, maxlen=max_length,\n",
        "                                                                          padding='post')\n",
        "                input_text_seq.append(input_seq)\n",
        "                if caption == num_captions:\n",
        "                    break\n",
        "            if batch_iter == num_photos_per_batch:\n",
        "                input_text_seq = np.concatenate(input_text_seq)\n",
        "                yield [np.array(images), np.array(input_text_seq)]\n",
        "                images, input_text_seq = list(), list()\n",
        "                batch_iter = 0"
      ],
      "metadata": {
        "id": "2CAacq12PSvG"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCnr1RqfG--K",
        "outputId": "f3105e38-5979-49dd-90d0-70d752099490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version 2.7.0\n",
            "max_length of captions 33\n",
            "max_length of captions 31\n",
            "max_length of captions 30\n",
            "No of captions: Training-6000.0 Validation-1000.0 test-1000.0\n",
            "Vocab size 5000\n",
            "Vocab size 5000\n",
            "Vocab size 5000\n",
            "(47, 256, 256, 3) (47, 25)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "#from data_processing import data_processing\n",
        "#from data_generator import captions_generation\n",
        "import pickle\n",
        "\n",
        "print('TensorFlow Version', tf.__version__)\n",
        "vocab_size = 5000\n",
        "max_length = 25\n",
        "\n",
        "\n",
        "captions_text_path = r'/content/Flickr8k.token.txt'\n",
        "captions_extraction = data_processing(captions_text_path)\n",
        "trn_images_id_text = r'/content/Flickr_8k.trainImages.txt'\n",
        "train_cleaned_seq, train_cleaned_dic = captions_extraction.cleaning_sequencing_captions(trn_images_id_text)\n",
        "val_images_id_text = r'/content/Flickr_8k.devImages.txt'\n",
        "val_cleaned_seq, val_cleaned_dic = captions_extraction.cleaning_sequencing_captions(val_images_id_text)\n",
        "test_images_id_text = r'/content/Flickr_8k.testImages.txt'\n",
        "test_cleaned_seq, test_cleaned_dic = captions_extraction.cleaning_sequencing_captions(test_images_id_text)\n",
        "captions_extraction.tokenization(train_cleaned_seq, vocab_size)\n",
        "print(\"No of captions: Training-\" + str(len(train_cleaned_seq) / 5) + \" Validation-\" + str(\n",
        "    len(val_cleaned_seq) / 5) + \" test-\" + str(len(test_cleaned_seq) / 5))\n",
        "\n",
        "train_cap_tok = captions_extraction.sentence_tokenizing(train_cleaned_dic)\n",
        "val_cap_tok = captions_extraction.sentence_tokenizing(val_cleaned_dic)\n",
        "test_cap_tok = captions_extraction.sentence_tokenizing(test_cleaned_dic)\n",
        "\n",
        "image_pth_rt = r\"/content/Flicker8k_Dataset/\" #+ r\"\\\\\"\n",
        "trn_dataset = captions_generation_reward(train_cap_tok, vocab_size, image_pth_rt, max_length,num_photos_per_batch=2,num_captions=1)\n",
        "val_dataset = captions_generation_reward(val_cap_tok, vocab_size, image_pth_rt, max_length)\n",
        "\n",
        "inputs = next(iter(val_dataset))\n",
        "print(inputs[0].shape, inputs[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trn_dataset_whole = captions_generation_reward(token_cap_dic, vocab_size, image_pth_rt, max_length,num_photos_per_batch=5,num_captions=5)"
      ],
      "metadata": {
        "id": "6x-SWJHw9Dq_"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reward_model = Caption_model_gen(NET='reward', vocab_size=5000, Embed_Size=512, max_length=max_length,display=True)\n",
        "#actor_model.summary()\n",
        "#reward_model.compile(loss=reward_net_loss,                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),                    metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqTIPCVxmrRb",
        "outputId": "6a276348-2a0a-44a2-8070-56d6679b2975"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building CNN model\n",
            "CNN model {output shape}: (None, 256)\n",
            "Building RNN model\n",
            "final_carry_state {rnn output shape}: (None, 512)\n",
            "Image feature vector shape: (None, 512)\n",
            "Text sequence vector shape: (None, 512)\n",
            "Reward Net built successfully \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(image_encoder,caption_encoder):\n",
        "    gamma=0.2\n",
        "    N,D=image_encoder.shape\n",
        "    img_encode = image_encoder\n",
        "    cap_encode = caption_encoder\n",
        "    scores_matrix = tf.matmul(img_encode,tf.transpose(cap_encode))\n",
        "    diagonal = tf.linalg.diag_part(scores_matrix)\n",
        "    cost_cap = tf.maximum(0.0, gamma - diagonal + scores_matrix)\n",
        "    diagonal = tf.reshape(diagonal, [-1, 1])\n",
        "    cost_img = tf.maximum(0.0, gamma - diagonal + scores_matrix)\n",
        "    cost_cap = tf.linalg.set_diag(cost_cap, [0]*N)\n",
        "    cost_img = tf.linalg.set_diag(cost_img, [0]*N)\n",
        "    loss = tf.reduce_sum(cost_img) + tf.reduce_sum(cost_cap)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "bYM0BVQumWsL"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss(visuals,semantics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H6E5eDzCrQl",
        "outputId": "c9e9afbe-af9b-40da-ef82-78993e502287"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=396.80002>"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cos(img_encode, cap_encode):\n",
        "    inner_product = tf.reduce_sum(tf.multiply(img_encode, cap_encode), axis=1)\n",
        "    norm1 = tf.sqrt(tf.reduce_sum(tf.square(img_encode), axis=1))\n",
        "    norm2 = tf.sqrt(tf.reduce_sum(tf.square(cap_encode), axis=1))\n",
        "    cos = inner_product / (norm1 * norm2)\n",
        "    return cos"
      ],
      "metadata": {
        "id": "iSC-8l9Zm2-B"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Rewards(reward_model,input):\n",
        "    visEmbeds, semEmbeds = reward_model(input)\n",
        "    inner_product = tf.reduce_sum(tf.multiply(visEmbeds, semEmbeds), axis=1)\n",
        "    norm1 = tf.sqrt(tf.reduce_sum(tf.square(visEmbeds), axis=1))\n",
        "    norm2 = tf.sqrt(tf.reduce_sum(tf.square(semEmbeds), axis=1))\n",
        "    cos = inner_product / (norm1 * norm2)\n",
        "    print(cos)\n",
        "    return cos"
      ],
      "metadata": {
        "id": "3ZugP37nUs8D"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reward_model1=tf.keras.models.load_model('/content/drive/MyDrive/Kaggle/reward_net.h5')"
      ],
      "metadata": {
        "id": "PFjyFb8LU7D5"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reward_model.save('/content/drive/MyDrive/Kaggle/reward_net.h5')"
      ],
      "metadata": {
        "id": "sx-b0YUBIf3D"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "history={}\n",
        "history['loss']=list()\n",
        "history['val_loss']=list()\n",
        "metrics_names = ['loss'] \n",
        "epochs = 1\n",
        "num_epoch=400\n",
        "for i in range(epochs):\n",
        "    n=0\n",
        "    epoch=0\n",
        "    for step, x_batch_train in enumerate(trn_dataset_whole):\n",
        "        if epoch==num_epoch:\n",
        "          break\n",
        "        progbar = tf.keras.utils.Progbar(10,stateful_metrics=['loss'])\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            [visual,sematic] = reward_model(x_batch_train, training=True)  # Logits for this minibatch\n",
        "            loss_value = loss(visual, sematic)\n",
        "        grads = tape.gradient(loss_value, reward_model.trainable_weights)\n",
        "\n",
        "        optimizer.apply_gradients(zip(grads, reward_model.trainable_weights))\n",
        "        progbar.update(n, values = [(\"loss\", loss_value)])\n",
        "        # Log every 200 batches.\n",
        "        n+=1\n",
        "        if step % 10 == 0:\n",
        "            epoch+=1\n",
        "            val_ds=next(iter(val_dataset))\n",
        "            [val_visual,val_sematic] = reward_model(val_ds)\n",
        "            val_loss_value=loss(val_visual, val_sematic)\n",
        "            progbar.add(1,values = [(\"val_loss\", val_loss_value)])\n",
        "            n=0\n",
        "            print(\"\\nepoch %d\" % (epoch,))\n",
        "            history['loss'].append(loss_value)\n",
        "            history['val_loss'].append(val_loss_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZuh0RCKlqYh",
        "outputId": "736d3725-c6a4-42e8-c7e8-4e3b73a1151a"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1/10 [==>...........................] - ETA: 4s - loss: 33.8575 - val_loss: 8.7390\n",
            "epoch 1\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 44.3347 - val_loss: 9.4053\n",
            "\n",
            "epoch 2\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 27.4112 - val_loss: 9.6651\n",
            "\n",
            "epoch 3\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 27.5526 - val_loss: 8.6949\n",
            "\n",
            "epoch 4\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 10.3849 - val_loss: 8.2126\n",
            "\n",
            "epoch 5\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 9.8615 - val_loss: 8.3936\n",
            "\n",
            "epoch 6\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 8.1175 - val_loss: 8.2235\n",
            "\n",
            "epoch 7\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9886 - val_loss: 8.0852\n",
            "\n",
            "epoch 8\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9863 - val_loss: 8.3172\n",
            "\n",
            "epoch 9\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9949 - val_loss: 8.6909\n",
            "\n",
            "epoch 10\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9806 - val_loss: 8.0451\n",
            "\n",
            "epoch 11\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9933 - val_loss: 8.3545\n",
            "\n",
            "epoch 12\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9905 - val_loss: 8.2079\n",
            "\n",
            "epoch 13\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.0103 - val_loss: 8.5979\n",
            "\n",
            "epoch 14\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9520 - val_loss: 8.0747\n",
            "\n",
            "epoch 15\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9816 - val_loss: 7.9756\n",
            "\n",
            "epoch 16\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9802 - val_loss: 8.1039\n",
            "\n",
            "epoch 17\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 7.8895 - val_loss: 8.0383\n",
            "\n",
            "epoch 18\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 7.9992 - val_loss: 8.2313\n",
            "\n",
            "epoch 19\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9502 - val_loss: 8.0520\n",
            "\n",
            "epoch 20\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9835 - val_loss: 8.4214\n",
            "\n",
            "epoch 21\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.0072 - val_loss: 8.0045\n",
            "\n",
            "epoch 22\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9540 - val_loss: 7.8675\n",
            "\n",
            "epoch 23\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.8929 - val_loss: 8.1087\n",
            "\n",
            "epoch 24\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.8052 - val_loss: 8.0558\n",
            "\n",
            "epoch 25\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.9330 - val_loss: 8.2613\n",
            "\n",
            "epoch 26\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9827 - val_loss: 8.1986\n",
            "\n",
            "epoch 27\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.0928 - val_loss: 10.3254\n",
            "\n",
            "epoch 28\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.8831 - val_loss: 14.1644\n",
            "\n",
            "epoch 29\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9584 - val_loss: 8.1676\n",
            "\n",
            "epoch 30\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 8.0596 - val_loss: 8.7298\n",
            "\n",
            "epoch 31\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.6775 - val_loss: 10.4076\n",
            "\n",
            "epoch 32\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9497 - val_loss: 10.9010\n",
            "\n",
            "epoch 33\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.7817 - val_loss: 8.7318\n",
            "\n",
            "epoch 34\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 11.8508 - val_loss: 9.4731\n",
            "\n",
            "epoch 35\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 6.2139 - val_loss: 8.4403\n",
            "\n",
            "epoch 36\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.2610 - val_loss: 7.6590\n",
            "\n",
            "epoch 37\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.3904 - val_loss: 7.8978\n",
            "\n",
            "epoch 38\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 10.7171 - val_loss: 7.8631\n",
            "\n",
            "epoch 39\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.2580 - val_loss: 13.6370\n",
            "\n",
            "epoch 40\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.1801 - val_loss: 8.6730\n",
            "\n",
            "epoch 41\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.6658 - val_loss: 10.5786\n",
            "\n",
            "epoch 42\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.3467 - val_loss: 10.5376\n",
            "\n",
            "epoch 43\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 6.7109 - val_loss: 15.3258\n",
            "\n",
            "epoch 44\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.2359 - val_loss: 11.4745\n",
            "\n",
            "epoch 45\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 7.9539 - val_loss: 9.3264\n",
            "\n",
            "epoch 46\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.1229 - val_loss: 5.0916\n",
            "\n",
            "epoch 47\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.3757 - val_loss: 6.7368\n",
            "\n",
            "epoch 48\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.1542 - val_loss: 7.7485\n",
            "\n",
            "epoch 49\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2751 - val_loss: 5.7033\n",
            "\n",
            "epoch 50\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.7317 - val_loss: 5.9196\n",
            "\n",
            "epoch 51\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.8217 - val_loss: 8.1716\n",
            "\n",
            "epoch 52\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.3309 - val_loss: 8.1513\n",
            "\n",
            "epoch 53\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.1670 - val_loss: 5.4664\n",
            "\n",
            "epoch 54\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.0250 - val_loss: 4.8481\n",
            "\n",
            "epoch 55\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.1505 - val_loss: 7.9815\n",
            "\n",
            "epoch 56\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.2220 - val_loss: 8.0311\n",
            "\n",
            "epoch 57\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.3438 - val_loss: 4.8176\n",
            "\n",
            "epoch 58\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.4683 - val_loss: 5.8069\n",
            "\n",
            "epoch 59\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 9.2928 - val_loss: 8.5374\n",
            "\n",
            "epoch 60\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.5221 - val_loss: 4.7361\n",
            "\n",
            "epoch 61\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.8862 - val_loss: 8.1182\n",
            "\n",
            "epoch 62\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.4244 - val_loss: 7.0085\n",
            "\n",
            "epoch 63\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 10.5310 - val_loss: 6.8001\n",
            "\n",
            "epoch 64\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.8047 - val_loss: 3.1791\n",
            "\n",
            "epoch 65\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.4382 - val_loss: 4.2995\n",
            "\n",
            "epoch 66\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.4742 - val_loss: 6.0179\n",
            "\n",
            "epoch 67\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.4003 - val_loss: 6.4136\n",
            "\n",
            "epoch 68\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.6536 - val_loss: 9.9466\n",
            "\n",
            "epoch 69\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 8.7165 - val_loss: 8.4622\n",
            "\n",
            "epoch 70\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.4388 - val_loss: 4.9669\n",
            "\n",
            "epoch 71\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 9.4951 - val_loss: 8.3567\n",
            "\n",
            "epoch 72\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.6994 - val_loss: 4.9836\n",
            "\n",
            "epoch 73\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 6.2617 - val_loss: 7.8227\n",
            "\n",
            "epoch 74\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 6.9514 - val_loss: 5.7417\n",
            "\n",
            "epoch 75\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.9333 - val_loss: 2.9879\n",
            "\n",
            "epoch 76\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9187 - val_loss: 3.1645\n",
            "\n",
            "epoch 77\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 7.4637 - val_loss: 8.0597\n",
            "\n",
            "epoch 78\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.8527 - val_loss: 4.8755\n",
            "\n",
            "epoch 79\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.4793 - val_loss: 5.0558\n",
            "\n",
            "epoch 80\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.0940 - val_loss: 6.9122\n",
            "\n",
            "epoch 81\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.9528 - val_loss: 7.9795\n",
            "\n",
            "epoch 82\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.5910 - val_loss: 7.4282\n",
            "\n",
            "epoch 83\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 12.8558 - val_loss: 7.8684\n",
            "\n",
            "epoch 84\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.1881 - val_loss: 8.9561\n",
            "\n",
            "epoch 85\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.3488 - val_loss: 4.8281\n",
            "\n",
            "epoch 86\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 8.1281 - val_loss: 3.5924\n",
            "\n",
            "epoch 87\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.4986 - val_loss: 8.3221\n",
            "\n",
            "epoch 88\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9697 - val_loss: 8.0962\n",
            "\n",
            "epoch 89\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.7761 - val_loss: 7.7880\n",
            "\n",
            "epoch 90\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.2577 - val_loss: 6.6963\n",
            "\n",
            "epoch 91\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.0928 - val_loss: 5.9316\n",
            "\n",
            "epoch 92\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.9434 - val_loss: 5.6175\n",
            "\n",
            "epoch 93\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.6482 - val_loss: 8.2729\n",
            "\n",
            "epoch 94\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.3342 - val_loss: 5.1218\n",
            "\n",
            "epoch 95\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.2762 - val_loss: 7.9236\n",
            "\n",
            "epoch 96\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.4510 - val_loss: 5.3489\n",
            "\n",
            "epoch 97\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.5305 - val_loss: 7.2220\n",
            "\n",
            "epoch 98\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.3094 - val_loss: 4.9324\n",
            "\n",
            "epoch 99\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.8903 - val_loss: 3.2188\n",
            "\n",
            "epoch 100\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.6291 - val_loss: 3.4167\n",
            "\n",
            "epoch 101\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 5.4574 - val_loss: 5.0040\n",
            "\n",
            "epoch 102\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9730 - val_loss: 8.2320\n",
            "\n",
            "epoch 103\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 6.3419 - val_loss: 6.3724\n",
            "\n",
            "epoch 104\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.9390 - val_loss: 8.2384\n",
            "\n",
            "epoch 105\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.4384 - val_loss: 3.9310\n",
            "\n",
            "epoch 106\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9127 - val_loss: 6.1935\n",
            "\n",
            "epoch 107\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.1996 - val_loss: 4.8074\n",
            "\n",
            "epoch 108\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 12.4841 - val_loss: 10.8467\n",
            "\n",
            "epoch 109\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.8551 - val_loss: 5.0601\n",
            "\n",
            "epoch 110\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.0203 - val_loss: 3.1946\n",
            "\n",
            "epoch 111\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.7225 - val_loss: 3.4396\n",
            "\n",
            "epoch 112\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.0324 - val_loss: 4.7616\n",
            "\n",
            "epoch 113\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.1817 - val_loss: 4.9146\n",
            "\n",
            "epoch 114\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.2045 - val_loss: 7.7379\n",
            "\n",
            "epoch 115\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.0897 - val_loss: 5.9559\n",
            "\n",
            "epoch 116\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.2402 - val_loss: 7.6874\n",
            "\n",
            "epoch 117\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.7992 - val_loss: 5.1643\n",
            "\n",
            "epoch 118\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.7825 - val_loss: 7.9691\n",
            "\n",
            "epoch 119\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.8195 - val_loss: 4.7592\n",
            "\n",
            "epoch 120\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.8597 - val_loss: 5.5620\n",
            "\n",
            "epoch 121\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.3255 - val_loss: 6.1044\n",
            "\n",
            "epoch 122\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.0591 - val_loss: 7.5084\n",
            "\n",
            "epoch 123\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.8562 - val_loss: 4.8737\n",
            "\n",
            "epoch 124\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.3424 - val_loss: 4.8225\n",
            "\n",
            "epoch 125\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.0755 - val_loss: 4.6556\n",
            "\n",
            "epoch 126\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.5108 - val_loss: 8.8783\n",
            "\n",
            "epoch 127\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9905 - val_loss: 5.5029\n",
            "\n",
            "epoch 128\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.1853 - val_loss: 8.5510\n",
            "\n",
            "epoch 129\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.5887 - val_loss: 10.4415\n",
            "\n",
            "epoch 130\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.5746 - val_loss: 5.8147\n",
            "\n",
            "epoch 131\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.8798 - val_loss: 6.9374\n",
            "\n",
            "epoch 132\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.1816 - val_loss: 4.7969\n",
            "\n",
            "epoch 133\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 5.4598 - val_loss: 4.8058\n",
            "\n",
            "epoch 134\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.6280 - val_loss: 3.2106\n",
            "\n",
            "epoch 135\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 7.5203 - val_loss: 8.3271\n",
            "\n",
            "epoch 136\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.2567 - val_loss: 5.1352\n",
            "\n",
            "epoch 137\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.7441 - val_loss: 7.5772\n",
            "\n",
            "epoch 138\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.8162 - val_loss: 3.2785\n",
            "\n",
            "epoch 139\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 11.0154 - val_loss: 3.6805\n",
            "\n",
            "epoch 140\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.6347 - val_loss: 5.2407\n",
            "\n",
            "epoch 141\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.7427 - val_loss: 4.3697\n",
            "\n",
            "epoch 142\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.1445 - val_loss: 7.9160\n",
            "\n",
            "epoch 143\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.3152 - val_loss: 5.0330\n",
            "\n",
            "epoch 144\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.3894 - val_loss: 7.0062\n",
            "\n",
            "epoch 145\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.2074 - val_loss: 7.9945\n",
            "\n",
            "epoch 146\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.3049 - val_loss: 3.7049\n",
            "\n",
            "epoch 147\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.9569 - val_loss: 4.9734\n",
            "\n",
            "epoch 148\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.6221 - val_loss: 4.9192\n",
            "\n",
            "epoch 149\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.3558 - val_loss: 6.3304\n",
            "\n",
            "epoch 150\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 9.1086 - val_loss: 7.4127\n",
            "\n",
            "epoch 151\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.0030 - val_loss: 8.4145\n",
            "\n",
            "epoch 152\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.9531 - val_loss: 5.3497\n",
            "\n",
            "epoch 153\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 7.2113 - val_loss: 3.2254\n",
            "\n",
            "epoch 154\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.7936 - val_loss: 7.9920\n",
            "\n",
            "epoch 155\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.3616 - val_loss: 5.5651\n",
            "\n",
            "epoch 156\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.4933 - val_loss: 7.9391\n",
            "\n",
            "epoch 157\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.7540 - val_loss: 4.9284\n",
            "\n",
            "epoch 158\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.0413 - val_loss: 4.3646\n",
            "\n",
            "epoch 159\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.7008 - val_loss: 7.7060\n",
            "\n",
            "epoch 160\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.8211 - val_loss: 8.0908\n",
            "\n",
            "epoch 161\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.9614 - val_loss: 7.2422\n",
            "\n",
            "epoch 162\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.3352 - val_loss: 7.9581\n",
            "\n",
            "epoch 163\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.8599 - val_loss: 3.2181\n",
            "\n",
            "epoch 164\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.1707 - val_loss: 5.0290\n",
            "\n",
            "epoch 165\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.1957 - val_loss: 8.0623\n",
            "\n",
            "epoch 166\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.9418 - val_loss: 4.7501\n",
            "\n",
            "epoch 167\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 9.4941 - val_loss: 9.2585\n",
            "\n",
            "epoch 168\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2396 - val_loss: 7.4478\n",
            "\n",
            "epoch 169\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.1068 - val_loss: 4.9222\n",
            "\n",
            "epoch 170\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.0059 - val_loss: 8.0041\n",
            "\n",
            "epoch 171\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.7128 - val_loss: 3.5217\n",
            "\n",
            "epoch 172\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2090 - val_loss: 8.9427\n",
            "\n",
            "epoch 173\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.5509 - val_loss: 9.4582\n",
            "\n",
            "epoch 174\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.0145 - val_loss: 8.9994\n",
            "\n",
            "epoch 175\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.5954 - val_loss: 4.8486\n",
            "\n",
            "epoch 176\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.9653 - val_loss: 6.5764\n",
            "\n",
            "epoch 177\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 6.4425 - val_loss: 5.3194\n",
            "\n",
            "epoch 178\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 6.8767 - val_loss: 3.3035\n",
            "\n",
            "epoch 179\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.8306 - val_loss: 12.4871\n",
            "\n",
            "epoch 180\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.9042 - val_loss: 6.8927\n",
            "\n",
            "epoch 181\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.8206 - val_loss: 3.6510\n",
            "\n",
            "epoch 182\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.8015 - val_loss: 4.7344\n",
            "\n",
            "epoch 183\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.4701 - val_loss: 7.3312\n",
            "\n",
            "epoch 184\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 7.9905 - val_loss: 7.5835\n",
            "\n",
            "epoch 185\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 4.4241 - val_loss: 4.8246\n",
            "\n",
            "epoch 186\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.7118 - val_loss: 7.9731\n",
            "\n",
            "epoch 187\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 7.6631 - val_loss: 7.9468\n",
            "\n",
            "epoch 188\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 7.5916 - val_loss: 4.8030\n",
            "\n",
            "epoch 189\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.7223 - val_loss: 7.9330\n",
            "\n",
            "epoch 190\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 4.8005 - val_loss: 3.2035\n",
            "\n",
            "epoch 191\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.3809 - val_loss: 3.1794\n",
            "\n",
            "epoch 192\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.9336 - val_loss: 3.2020\n",
            "\n",
            "epoch 193\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.2029 - val_loss: 6.8871\n",
            "\n",
            "epoch 194\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 7.9936 - val_loss: 5.9302\n",
            "\n",
            "epoch 195\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.2031 - val_loss: 4.9989\n",
            "\n",
            "epoch 196\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.5847 - val_loss: 4.2694\n",
            "\n",
            "epoch 197\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 9.1291 - val_loss: 4.7840\n",
            "\n",
            "epoch 198\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.6735 - val_loss: 6.4678\n",
            "\n",
            "epoch 199\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.5495 - val_loss: 4.9038\n",
            "\n",
            "epoch 200\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.7653 - val_loss: 7.0944\n",
            "\n",
            "epoch 201\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2228 - val_loss: 7.2655\n",
            "\n",
            "epoch 202\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.6856 - val_loss: 3.1846\n",
            "\n",
            "epoch 203\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.2319 - val_loss: 7.8035\n",
            "\n",
            "epoch 204\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.0015 - val_loss: 4.3009\n",
            "\n",
            "epoch 205\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.3033 - val_loss: 14.5189\n",
            "\n",
            "epoch 206\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 5.0029 - val_loss: 4.9733\n",
            "\n",
            "epoch 207\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.1597 - val_loss: 4.6291\n",
            "\n",
            "epoch 208\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2147 - val_loss: 4.7154\n",
            "\n",
            "epoch 209\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.9077 - val_loss: 6.0837\n",
            "\n",
            "epoch 210\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.3302 - val_loss: 3.4754\n",
            "\n",
            "epoch 211\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.2613 - val_loss: 4.6439\n",
            "\n",
            "epoch 212\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 9.3602 - val_loss: 4.8436\n",
            "\n",
            "epoch 213\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.4432 - val_loss: 8.2241\n",
            "\n",
            "epoch 214\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.3212 - val_loss: 3.2096\n",
            "\n",
            "epoch 215\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2092 - val_loss: 7.4729\n",
            "\n",
            "epoch 216\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.5715 - val_loss: 4.8010\n",
            "\n",
            "epoch 217\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 5.7426 - val_loss: 8.8248\n",
            "\n",
            "epoch 218\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.2050 - val_loss: 6.1423\n",
            "\n",
            "epoch 219\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.5515 - val_loss: 7.9443\n",
            "\n",
            "epoch 220\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.3008 - val_loss: 9.5253\n",
            "\n",
            "epoch 221\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.0779 - val_loss: 3.8011\n",
            "\n",
            "epoch 222\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.4200 - val_loss: 12.5649\n",
            "\n",
            "epoch 223\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 9.3773 - val_loss: 8.5666\n",
            "\n",
            "epoch 224\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.8106 - val_loss: 5.4509\n",
            "\n",
            "epoch 225\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.3462 - val_loss: 4.9527\n",
            "\n",
            "epoch 226\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.5609 - val_loss: 9.3665\n",
            "\n",
            "epoch 227\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.8361 - val_loss: 9.0536\n",
            "\n",
            "epoch 228\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.7870 - val_loss: 8.0052\n",
            "\n",
            "epoch 229\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.4056 - val_loss: 5.8261\n",
            "\n",
            "epoch 230\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.7598 - val_loss: 6.0013\n",
            "\n",
            "epoch 231\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.0036 - val_loss: 5.3714\n",
            "\n",
            "epoch 232\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.3391 - val_loss: 7.8631\n",
            "\n",
            "epoch 233\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.8279 - val_loss: 4.5388\n",
            "\n",
            "epoch 234\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 8.1052 - val_loss: 3.1650\n",
            "\n",
            "epoch 235\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.0399 - val_loss: 10.2690\n",
            "\n",
            "epoch 236\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.4474 - val_loss: 3.1655\n",
            "\n",
            "epoch 237\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2737 - val_loss: 9.0622\n",
            "\n",
            "epoch 238\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.4705 - val_loss: 10.0036\n",
            "\n",
            "epoch 239\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9200 - val_loss: 7.3874\n",
            "\n",
            "epoch 240\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9683 - val_loss: 3.0625\n",
            "\n",
            "epoch 241\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2060 - val_loss: 8.0700\n",
            "\n",
            "epoch 242\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.9821 - val_loss: 5.1528\n",
            "\n",
            "epoch 243\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.0627 - val_loss: 7.6499\n",
            "\n",
            "epoch 244\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 5.2539 - val_loss: 8.1643\n",
            "\n",
            "epoch 245\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 4.8477 - val_loss: 4.9175\n",
            "\n",
            "epoch 246\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.2319 - val_loss: 5.2908\n",
            "\n",
            "epoch 247\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.6762 - val_loss: 4.7843\n",
            "\n",
            "epoch 248\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 6.9433 - val_loss: 7.8170\n",
            "\n",
            "epoch 249\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.7323 - val_loss: 5.9388\n",
            "\n",
            "epoch 250\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.3541 - val_loss: 5.5753\n",
            "\n",
            "epoch 251\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.9712 - val_loss: 5.9475\n",
            "\n",
            "epoch 252\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.7656 - val_loss: 9.8742\n",
            "\n",
            "epoch 253\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.7487 - val_loss: 9.5142\n",
            "\n",
            "epoch 254\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.4792 - val_loss: 3.3321\n",
            "\n",
            "epoch 255\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.0182 - val_loss: 8.1659\n",
            "\n",
            "epoch 256\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 6.9721 - val_loss: 7.9452\n",
            "\n",
            "epoch 257\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9952 - val_loss: 4.0289\n",
            "\n",
            "epoch 258\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.1895 - val_loss: 4.7706\n",
            "\n",
            "epoch 259\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.8935 - val_loss: 8.0377\n",
            "\n",
            "epoch 260\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 6.6820 - val_loss: 4.7893\n",
            "\n",
            "epoch 261\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.1424 - val_loss: 7.8344\n",
            "\n",
            "epoch 262\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 9.4418 - val_loss: 7.5654\n",
            "\n",
            "epoch 263\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.7070 - val_loss: 5.0168\n",
            "\n",
            "epoch 264\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.1499 - val_loss: 3.2936\n",
            "\n",
            "epoch 265\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.9163 - val_loss: 3.8124\n",
            "\n",
            "epoch 266\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.5453 - val_loss: 7.0497\n",
            "\n",
            "epoch 267\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.2755 - val_loss: 4.7365\n",
            "\n",
            "epoch 268\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.8956 - val_loss: 8.3302\n",
            "\n",
            "epoch 269\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.1799 - val_loss: 6.8448\n",
            "\n",
            "epoch 270\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.1076 - val_loss: 4.8819\n",
            "\n",
            "epoch 271\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.2724 - val_loss: 8.0274\n",
            "\n",
            "epoch 272\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.1884 - val_loss: 8.0355\n",
            "\n",
            "epoch 273\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9737 - val_loss: 7.9668\n",
            "\n",
            "epoch 274\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.4653 - val_loss: 6.7280\n",
            "\n",
            "epoch 275\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.8704 - val_loss: 3.1134\n",
            "\n",
            "epoch 276\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.5228 - val_loss: 5.4240\n",
            "\n",
            "epoch 277\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 6.0311 - val_loss: 8.2894\n",
            "\n",
            "epoch 278\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 5.0722 - val_loss: 4.8856\n",
            "\n",
            "epoch 279\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.9248 - val_loss: 6.2054\n",
            "\n",
            "epoch 280\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.8720 - val_loss: 8.0122\n",
            "\n",
            "epoch 281\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.1715 - val_loss: 7.9793\n",
            "\n",
            "epoch 282\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.6077 - val_loss: 8.1930\n",
            "\n",
            "epoch 283\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9606 - val_loss: 8.0093\n",
            "\n",
            "epoch 284\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.1338 - val_loss: 8.8453\n",
            "\n",
            "epoch 285\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 10.1757 - val_loss: 4.7905\n",
            "\n",
            "epoch 286\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 6.1448 - val_loss: 3.9331\n",
            "\n",
            "epoch 287\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 8.0151 - val_loss: 7.8493\n",
            "\n",
            "epoch 288\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.9291 - val_loss: 8.1605\n",
            "\n",
            "epoch 289\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 3.1952 - val_loss: 7.6566\n",
            "\n",
            "epoch 290\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 3.6326 - val_loss: 4.7587\n",
            "\n",
            "epoch 291\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 6.5298 - val_loss: 6.4858\n",
            "\n",
            "epoch 292\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.2978 - val_loss: 5.1339\n",
            "\n",
            "epoch 293\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.1378 - val_loss: 8.7003\n",
            "\n",
            "epoch 294\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.6808 - val_loss: 7.1575\n",
            "\n",
            "epoch 295\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.8368 - val_loss: 8.3811\n",
            "\n",
            "epoch 296\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 3.0900 - val_loss: 7.2342\n",
            "\n",
            "epoch 297\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.0433 - val_loss: 8.8165\n",
            "\n",
            "epoch 298\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 10.3285 - val_loss: 5.2171\n",
            "\n",
            "epoch 299\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.4870 - val_loss: 3.0477\n",
            "\n",
            "epoch 300\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.7843 - val_loss: 5.2310\n",
            "\n",
            "epoch 301\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 6.3320 - val_loss: 4.9833\n",
            "\n",
            "epoch 302\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.5515 - val_loss: 6.9319\n",
            "\n",
            "epoch 303\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9984 - val_loss: 4.7738\n",
            "\n",
            "epoch 304\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.1799 - val_loss: 7.9251\n",
            "\n",
            "epoch 305\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.7995 - val_loss: 3.3731\n",
            "\n",
            "epoch 306\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.7035 - val_loss: 4.9125\n",
            "\n",
            "epoch 307\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.2632 - val_loss: 5.1975\n",
            "\n",
            "epoch 308\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.0052 - val_loss: 9.5980\n",
            "\n",
            "epoch 309\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 10.1495 - val_loss: 8.4593\n",
            "\n",
            "epoch 310\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.8262 - val_loss: 3.2231\n",
            "\n",
            "epoch 311\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.3189 - val_loss: 3.6213\n",
            "\n",
            "epoch 312\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.2502 - val_loss: 4.7593\n",
            "\n",
            "epoch 313\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.8642 - val_loss: 5.3527\n",
            "\n",
            "epoch 314\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.4007 - val_loss: 8.8776\n",
            "\n",
            "epoch 315\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.3711 - val_loss: 9.2723\n",
            "\n",
            "epoch 316\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 9.0529 - val_loss: 7.7119\n",
            "\n",
            "epoch 317\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9706 - val_loss: 6.4623\n",
            "\n",
            "epoch 318\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.8407 - val_loss: 7.6539\n",
            "\n",
            "epoch 319\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.8954 - val_loss: 4.8072\n",
            "\n",
            "epoch 320\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 9.0813 - val_loss: 5.8692\n",
            "\n",
            "epoch 321\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.2295 - val_loss: 7.5285\n",
            "\n",
            "epoch 322\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.4419 - val_loss: 6.9032\n",
            "\n",
            "epoch 323\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.8458 - val_loss: 5.4270\n",
            "\n",
            "epoch 324\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.1981 - val_loss: 5.0214\n",
            "\n",
            "epoch 325\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.5336 - val_loss: 3.2010\n",
            "\n",
            "epoch 326\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.7859 - val_loss: 10.7962\n",
            "\n",
            "epoch 327\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 8.0776 - val_loss: 3.5406\n",
            "\n",
            "epoch 328\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.6618 - val_loss: 8.1784\n",
            "\n",
            "epoch 329\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.0420 - val_loss: 9.0066\n",
            "\n",
            "epoch 330\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.4730 - val_loss: 7.9408\n",
            "\n",
            "epoch 331\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 7.9238 - val_loss: 11.6761\n",
            "\n",
            "epoch 332\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.8443 - val_loss: 3.9465\n",
            "\n",
            "epoch 333\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 4.7969 - val_loss: 6.5753\n",
            "\n",
            "epoch 334\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.3638 - val_loss: 3.3902\n",
            "\n",
            "epoch 335\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.6265 - val_loss: 8.0687\n",
            "\n",
            "epoch 336\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 9.2300 - val_loss: 7.4880\n",
            "\n",
            "epoch 337\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2542 - val_loss: 8.9741\n",
            "\n",
            "epoch 338\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.9361 - val_loss: 3.7609\n",
            "\n",
            "epoch 339\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.3302 - val_loss: 7.9794\n",
            "\n",
            "epoch 340\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 9.3920 - val_loss: 8.5932\n",
            "\n",
            "epoch 341\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.4641 - val_loss: 5.3286\n",
            "\n",
            "epoch 342\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2158 - val_loss: 7.9420\n",
            "\n",
            "epoch 343\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.8638 - val_loss: 4.7669\n",
            "\n",
            "epoch 344\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.7556 - val_loss: 6.1723\n",
            "\n",
            "epoch 345\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.2485 - val_loss: 8.4073\n",
            "\n",
            "epoch 346\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.3102 - val_loss: 2.9501\n",
            "\n",
            "epoch 347\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 9.6251 - val_loss: 4.8872\n",
            "\n",
            "epoch 348\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.8385 - val_loss: 5.2030\n",
            "\n",
            "epoch 349\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 8.0210 - val_loss: 9.3670\n",
            "\n",
            "epoch 350\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.9792 - val_loss: 3.1137\n",
            "\n",
            "epoch 351\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.7006 - val_loss: 7.8684\n",
            "\n",
            "epoch 352\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.7996 - val_loss: 4.6992\n",
            "\n",
            "epoch 353\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.3429 - val_loss: 3.2042\n",
            "\n",
            "epoch 354\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.8118 - val_loss: 7.7101\n",
            "\n",
            "epoch 355\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.8069 - val_loss: 3.3142\n",
            "\n",
            "epoch 356\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.0916 - val_loss: 8.1272\n",
            "\n",
            "epoch 357\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.1880 - val_loss: 8.8495\n",
            "\n",
            "epoch 358\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.4942 - val_loss: 4.2006\n",
            "\n",
            "epoch 359\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9232 - val_loss: 7.9783\n",
            "\n",
            "epoch 360\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.2643 - val_loss: 10.8580\n",
            "\n",
            "epoch 361\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.3389 - val_loss: 10.0407\n",
            "\n",
            "epoch 362\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.3944 - val_loss: 7.6596\n",
            "\n",
            "epoch 363\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 3.2105 - val_loss: 6.1575\n",
            "\n",
            "epoch 364\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 4.4704 - val_loss: 4.8185\n",
            "\n",
            "epoch 365\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 3.2660 - val_loss: 8.0259\n",
            "\n",
            "epoch 366\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.1197 - val_loss: 5.0243\n",
            "\n",
            "epoch 367\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 9.7543 - val_loss: 7.9940\n",
            "\n",
            "epoch 368\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.1958 - val_loss: 7.8573\n",
            "\n",
            "epoch 369\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.2597 - val_loss: 5.8674\n",
            "\n",
            "epoch 370\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9197 - val_loss: 7.9767\n",
            "\n",
            "epoch 371\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.5288 - val_loss: 8.2331\n",
            "\n",
            "epoch 372\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.0912 - val_loss: 9.8161\n",
            "\n",
            "epoch 373\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.3993 - val_loss: 12.9439\n",
            "\n",
            "epoch 374\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.6143 - val_loss: 8.6299\n",
            "\n",
            "epoch 375\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.9232 - val_loss: 4.8324\n",
            "\n",
            "epoch 376\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 3.7376 - val_loss: 12.0131\n",
            "\n",
            "epoch 377\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.7969 - val_loss: 4.7492\n",
            "\n",
            "epoch 378\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 6.6712 - val_loss: 6.0716\n",
            "\n",
            "epoch 379\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.4844 - val_loss: 7.3240\n",
            "\n",
            "epoch 380\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.5550 - val_loss: 6.0088\n",
            "\n",
            "epoch 381\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.0383 - val_loss: 3.5716\n",
            "\n",
            "epoch 382\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.6145 - val_loss: 5.2488\n",
            "\n",
            "epoch 383\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 3.0719 - val_loss: 5.5746\n",
            "\n",
            "epoch 384\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.6732 - val_loss: 8.1632\n",
            "\n",
            "epoch 385\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 5.8763 - val_loss: 5.2461\n",
            "\n",
            "epoch 386\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 6.2265 - val_loss: 7.9205\n",
            "\n",
            "epoch 387\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9663 - val_loss: 8.7848\n",
            "\n",
            "epoch 388\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.2095 - val_loss: 4.7772\n",
            "\n",
            "epoch 389\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 7.7829 - val_loss: 8.9728\n",
            "\n",
            "epoch 390\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 7.8052 - val_loss: 2.9686\n",
            "\n",
            "epoch 391\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 7.9746 - val_loss: 3.1850\n",
            "\n",
            "epoch 392\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 7.9908 - val_loss: 3.8953\n",
            "\n",
            "epoch 393\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 5.2380 - val_loss: 6.0916\n",
            "\n",
            "epoch 394\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 4.9364 - val_loss: 6.6220\n",
            "\n",
            "epoch 395\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.6428 - val_loss: 4.7644\n",
            "\n",
            "epoch 396\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 8.1374 - val_loss: 4.4918\n",
            "\n",
            "epoch 397\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 8.4498 - val_loss: 4.7807\n",
            "\n",
            "epoch 398\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.6356 - val_loss: 6.6465\n",
            "\n",
            "epoch 399\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 4.5211 - val_loss: 4.8398\n",
            "\n",
            "epoch 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/reward_net_whole_training_lstm_1.pkl\", \"wb\")\n",
        "pickle.dump(history, f)\n",
        "f.close()   "
      ],
      "metadata": {
        "id": "mP6E0oKE4-MJ"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "R7pbfXY44R8n"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.axis([150,250,0,25])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "rjYWCRIZ4JX-",
        "outputId": "38a1ab33-766c-4ee2-f3fe-936b779e848b"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150.0, 250.0, 0.0, 25.0)"
            ]
          },
          "metadata": {},
          "execution_count": 208
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reward_model.save('/content/drive/MyDrive/Kaggle/reward_net.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnR_hOQC4Do4",
        "outputId": "ce56ca16-a642-4e77-e6d5-29e3ca46cb17"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = next(iter(trn_dataset))\n",
        "print(inputs[0].shape, inputs[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl686AqOb2dY",
        "outputId": "8618ba53-c754-457e-9cb6-1796bffd8f57"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23, 256, 256, 3) (23, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rewards(reward_model,[inputs[0], inputs[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4ldPSuObxDG",
        "outputId": "b84098a5-c523-4f7a-c8c1-d345bd4f0409"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.1714517  -0.08112587 -0.0421367  -0.07938948 -0.06951115  0.00896424\n",
            " -0.07128771  0.00073981  0.05484186 -0.0505094  -0.02855068  0.04097078\n",
            " -0.06991029 -0.03773518 -0.09498962 -0.18582702 -0.12046738  0.13599293\n",
            "  0.03389726  0.00137834  0.06450967  0.09902795  0.06705884], shape=(23,), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(23,), dtype=float32, numpy=\n",
              "array([-0.1714517 , -0.08112587, -0.0421367 , -0.07938948, -0.06951115,\n",
              "        0.00896424, -0.07128771,  0.00073981,  0.05484186, -0.0505094 ,\n",
              "       -0.02855068,  0.04097078, -0.06991029, -0.03773518, -0.09498962,\n",
              "       -0.18582702, -0.12046738,  0.13599293,  0.03389726,  0.00137834,\n",
              "        0.06450967,  0.09902795,  0.06705884], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reward_model.save('/content/drive/MyDrive/Kaggle/reward_net.h5')"
      ],
      "metadata": {
        "id": "2F96IVlyKFj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c284f55-a9d0-4731-b589-706d91fc1323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reward_model=tf.keras.models.load_model('/content/drive/MyDrive/Kaggle/reward_net.h5')\n",
        "#actor_model.summary()\n",
        "#reward_model.compile(loss=reward_net_loss,                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),                    metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4YVkrm6Knnl",
        "outputId": "9cf619eb-cbe0-43f4-ef80-08809e3d6318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = next(iter(val_dataset))\n",
        "print(inputs[0].shape, inputs[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhFihdZZ4EEH",
        "outputId": "19b31047-7236-43ac-a6b5-3dd21098153a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 256, 256, 3) (5, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=Rewards(reward_model,[inputs[0], inputs[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdr6mgt439pQ",
        "outputId": "7adeb6f3-263e-46dc-ccf7-81a9ed88808a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.31575733 0.40269744 0.40483108 0.24068792 0.21883138], shape=(5,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'/content/drive/MyDrive/Kaggle/reward_net.h5'"
      ],
      "metadata": {
        "id": "-wl_u-KQKkE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i7Ii2EWF2hd",
        "outputId": "208ed1f7-19aa-4b80-c7fc-e56006ffc95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'val_loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/history_reward_model_Adam_incp_lstm_3.pkl\", \"wb\")\n",
        "pickle.dump(history, f)\n",
        "f.close() "
      ],
      "metadata": {
        "id": "sH35PugRynW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reward_model.save_weights('/content/reward_net_model_weights.h5')"
      ],
      "metadata": {
        "id": "Uxv7qvEeE9Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Rewards(model,features, captions):\n",
        "    visEmbeds, semEmbeds = model(features, captions)\n",
        "    visEmbeds=tf.norm\n",
        "    visEmbeds = F.normalize(visEmbeds, p=2, dim=1) \n",
        "    semEmbeds = F.normalize(semEmbeds, p=2, dim=1) \n",
        "    rewards = torch.sum(visEmbeds*semEmbeds, axis=1).unsqueeze(1)\n",
        "    return rewards"
      ],
      "metadata": {
        "id": "bGa4dwvB5crU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "training reward_net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ADb8JWK0oMC1Pa0UJ7Ig4vObsTPsqxHH",
      "authorship_tag": "ABX9TyMxwF28xxLyf3bTQJ7U9LiP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}